{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decanter AI Core SDK Jupyter Notebook Example\n",
    "This example provides how to use the python package decanter-ai-core-sdk, including installation, usage of the apis, and some ways to show chart of the experiment's attributes and data values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install decanter-ai-core-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from decanter import core\n",
    "from decanter.core.core_api import TrainInput, PredictInput\n",
    "from decanter.core.enums.algorithms import Algos as Alg\n",
    "from decanter.core.enums.evaluators import Evaluator as Eva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Context\n",
    "Create Context will set the connection to decanter core server, and create an event loop. Since Jupyter already have an event loop, SDK will just use the current event loop. See more in [here](https://www.notion.so/API-615d2fba4e7f45c4b5fe63cc192e481f#bb4f0a4b2847450abc4f80b025469170)\n",
    "\n",
    "In Jupyter, it will initially exist a running event loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "loop = asyncio.get_running_loop()\n",
    "loop.is_running()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: It is ok to recreate context to set the usr, pwd, host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable default logger\n",
    "core.enable_default_logger()\n",
    "# set the username, password, host\n",
    "context = core.Context.create(\n",
    "        username='{usr}', password='{pwd}', host='{decantercoreserver}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Decanter Core Client\n",
    "CoreClient handles the actions of calling api and getting the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = core.CoreClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of using `core.upload`, `core.train`, `core.predict`.\n",
    "While it's running, it'll show up the progress bar showing the progress of current running jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open train & test file\n",
    "train_file_path = os.path.join('{train_file_path}')\n",
    "test_file_path = os.path.join('{test_file_path}')\n",
    "train_file = open(train_file_path , 'r')\n",
    "test_file = open(test_file_path , 'r')\n",
    "\n",
    "# upload data to corex \n",
    "train_data = client.upload(file=train_file, name=\"train_data\")\n",
    "test_data = client.upload(file=test_file, name=\"test_data\")\n",
    "# from decanter.core.jobs import DataUpload\n",
    "# train_data = DataUpload.create(data_id = \"{data_id}\", name=\"train_data\")\n",
    "\n",
    "# set train parameters train model\n",
    "train_input = TrainInput(data=train_data, target='Survived', algos=[Alg.XGBoost], max_model=2, tolerance=0.9)\n",
    "exp = client.train(train_input=train_input, select_model_by=Eva.mean_per_class_error, name='myexp')\n",
    "\n",
    "# set predict parameters and predict result\n",
    "predict_input = PredictInput(data=test_data, experiment=exp)\n",
    "pred_res = client.predict(predict_input=predict_input, name='mypred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To prevent getting attributes when corresponding jobs aren't finished\n",
    "exp.get(attr='attributes')\n",
    "exp.best_model.get(attr='importances')\n",
    "pred_res.get(attr='schema')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Data\n",
    "Use `data.show_df()` and `predict_result.show_df()` to create pandas dataframe. <br>\n",
    "Use `data.show()` or `predict_result.show()` to show data in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.show_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show models attributes\n",
    "List the attributes you wish to see in a list, and call `core.plot.show_model_attr(attrs, exp)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core.plot.show_model_attr(metric=Eva.mean_per_class_error, score_types=['validation', 'cv_averages'], exp=exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data values with Data instance\n",
    "Plot chart with the values in data instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "labels = ['Survied', 'Dead']\n",
    "labels_gender = ['male', 'female', 'male', 'female']\n",
    "\n",
    "\n",
    "df = train_data.show_df()\n",
    "df_s = df.loc[df[\"Survived\"] == 1]\n",
    "df_d = df.loc[df[\"Survived\"] == 0]\n",
    "\n",
    "sizes = [df_s.shape[0], df_d.shape[0]]\n",
    "\n",
    "sizes_gender = []\n",
    "for d in [df_s, df_d]:\n",
    "    s1 = d.loc[d[\"Sex\"] == \"male\"].shape[0]\n",
    "    s2 = d.loc[d[\"Sex\"] == \"female\"].shape[0]\n",
    "    sizes_gender.append(s1)\n",
    "    sizes_gender.append(s2)\n",
    "\n",
    "    \n",
    "colors = ['#99ff99', '#ff6666']\n",
    "colors_gender = ['#87CEFA','#FFB6C1', '#87CEFA','#FFB6C1']\n",
    " \n",
    "# Plot\n",
    "plt.pie(sizes, labels=labels, colors=colors, startangle=90,frame=True)\n",
    "plt.pie(sizes_gender,colors=colors_gender ,radius=0.75,startangle=90)\n",
    "centre_circle = plt.Circle((0,0),0.5,color='black', fc='white',linewidth=0)\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    " \n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
